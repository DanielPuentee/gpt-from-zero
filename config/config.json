{
  "model": {
    "vocab_size": 1000,
    "d_model": 128,
    "n_heads": 4,
    "n_layers": 4,
    "d_ff": 512,
    "max_seq_len": 64,
    "dropout": 0.1
  },
  "training": {
    "batch_size": 8,
    "learning_rate": 0.0003,
    "n_epochs": 5,
    "device": "cpu"
  },
  "finetuning": {
    "pretrained_checkpoint": "model_epoch5.pt",
    "batch_size": 8,
    "learning_rate": 1e-5,
    "n_epochs": 5,
    "device": "cpu"
  }
}