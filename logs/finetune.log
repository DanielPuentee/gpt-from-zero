2026-02-03 14:54:12.271 | INFO     | __main__:finetune:192 - Using device: cpu
2026-02-03 14:54:12.277 | INFO     | __main__:finetune:204 - Loading pretrained model from checkpoints/model_epoch5.pt
2026-02-03 14:54:12.392 | DEBUG    | components.token_embedding:__init__:24 - TokenEmbedding: vocab=1000, dim=128
2026-02-03 14:54:12.392 | DEBUG    | components.positional_encoding:__init__:54 - SinusoidalPositionalEncoding: max_len=64, dim=128, dropout=0.1
2026-02-03 14:54:12.393 | DEBUG    | components.input_embeddings:__init__:31 - InputEmbeddings: vocab=1000, dim=128, max_len=64, dropout=0.1
2026-02-03 14:54:12.393 | DEBUG    | components.layer_norm:__init__:24 - LayerNorm: d_model=128, eps=1e-06
2026-02-03 14:54:12.393 | DEBUG    | components.layer_norm:__init__:24 - LayerNorm: d_model=128, eps=1e-06
2026-02-03 14:54:12.393 | DEBUG    | components.attention:__init__:54 - CausalSelfAttention: d_model=128, n_heads=4, head_dim=32, dropout=0.1
2026-02-03 14:54:12.394 | DEBUG    | components.feedforward:__init__:44 - FeedForward: d_model=128, d_ff=512, activation=gelu, dropout=0.1
2026-02-03 14:54:12.394 | DEBUG    | components.transformer_block:__init__:37 - TransformerBlock: d_model=128, n_heads=4, d_ff=512
2026-02-03 14:54:12.394 | DEBUG    | components.layer_norm:__init__:24 - LayerNorm: d_model=128, eps=1e-06
2026-02-03 14:54:12.394 | DEBUG    | components.layer_norm:__init__:24 - LayerNorm: d_model=128, eps=1e-06
2026-02-03 14:54:12.395 | DEBUG    | components.attention:__init__:54 - CausalSelfAttention: d_model=128, n_heads=4, head_dim=32, dropout=0.1
2026-02-03 14:54:12.396 | DEBUG    | components.feedforward:__init__:44 - FeedForward: d_model=128, d_ff=512, activation=gelu, dropout=0.1
2026-02-03 14:54:12.396 | DEBUG    | components.transformer_block:__init__:37 - TransformerBlock: d_model=128, n_heads=4, d_ff=512
2026-02-03 14:54:12.396 | DEBUG    | components.layer_norm:__init__:24 - LayerNorm: d_model=128, eps=1e-06
2026-02-03 14:54:12.396 | DEBUG    | components.layer_norm:__init__:24 - LayerNorm: d_model=128, eps=1e-06
2026-02-03 14:54:12.396 | DEBUG    | components.attention:__init__:54 - CausalSelfAttention: d_model=128, n_heads=4, head_dim=32, dropout=0.1
2026-02-03 14:54:12.398 | DEBUG    | components.feedforward:__init__:44 - FeedForward: d_model=128, d_ff=512, activation=gelu, dropout=0.1
2026-02-03 14:54:12.398 | DEBUG    | components.transformer_block:__init__:37 - TransformerBlock: d_model=128, n_heads=4, d_ff=512
2026-02-03 14:54:12.398 | DEBUG    | components.layer_norm:__init__:24 - LayerNorm: d_model=128, eps=1e-06
2026-02-03 14:54:12.398 | DEBUG    | components.layer_norm:__init__:24 - LayerNorm: d_model=128, eps=1e-06
2026-02-03 14:54:12.402 | DEBUG    | components.attention:__init__:54 - CausalSelfAttention: d_model=128, n_heads=4, head_dim=32, dropout=0.1
2026-02-03 14:54:12.403 | DEBUG    | components.feedforward:__init__:44 - FeedForward: d_model=128, d_ff=512, activation=gelu, dropout=0.1
2026-02-03 14:54:12.403 | DEBUG    | components.transformer_block:__init__:37 - TransformerBlock: d_model=128, n_heads=4, d_ff=512
2026-02-03 14:54:12.404 | INFO     | components.model:__init__:58 - GPTModel initialized: vocab=1000, d_model=128, n_heads=4, n_layers=4, d_ff=512, max_seq_len=64
2026-02-03 14:54:12.404 | INFO     | components.model:__init__:64 - Total parameters: 919,296
2026-02-03 14:54:12.406 | INFO     | __main__:finetune:215 - Pretrained model loaded successfully
2026-02-03 14:54:12.406 | INFO     | __main__:__init__:32 - Loading ratings from data/fine_tune_data.csv
2026-02-03 14:54:12.445 | INFO     | __main__:__init__:51 - Loaded 100 prompt-response pairs
2026-02-03 14:54:12.446 | INFO     | __main__:__init__:52 - Rating distribution: {5: 20, 4: 20, 3: 20, 2: 20, 1: 20}
2026-02-03 14:54:13.517 | INFO     | __main__:finetune:231 - Starting fine-tuning...
2026-02-03 14:54:14.221 | INFO     | __main__:finetune:279 - Epoch 1 completed. Average loss: 4.6905
2026-02-03 14:54:14.243 | INFO     | __main__:finetune:293 - Checkpoint saved: checkpoints/model_finetuned_epoch1.pt
2026-02-03 14:54:14.923 | INFO     | __main__:finetune:272 - Step 50, Loss: 4.8445, Avg batch rating: 3.8
2026-02-03 14:54:14.923 | INFO     | __main__:finetune:279 - Epoch 2 completed. Average loss: 4.6090
2026-02-03 14:54:14.944 | INFO     | __main__:finetune:293 - Checkpoint saved: checkpoints/model_finetuned_epoch2.pt
2026-02-03 14:54:15.598 | INFO     | __main__:finetune:279 - Epoch 3 completed. Average loss: 4.4468
2026-02-03 14:54:15.614 | INFO     | __main__:finetune:293 - Checkpoint saved: checkpoints/model_finetuned_epoch3.pt
2026-02-03 14:54:16.306 | INFO     | __main__:finetune:272 - Step 100, Loss: 6.0545, Avg batch rating: 4.2
2026-02-03 14:54:16.307 | INFO     | __main__:finetune:279 - Epoch 4 completed. Average loss: 4.3095
2026-02-03 14:54:16.329 | INFO     | __main__:finetune:293 - Checkpoint saved: checkpoints/model_finetuned_epoch4.pt
2026-02-03 14:54:17.039 | INFO     | __main__:finetune:279 - Epoch 5 completed. Average loss: 4.2520
2026-02-03 14:54:17.062 | INFO     | __main__:finetune:293 - Checkpoint saved: checkpoints/model_finetuned_epoch5.pt
2026-02-03 14:54:17.062 | INFO     | __main__:finetune:295 - Fine-tuning completed!
