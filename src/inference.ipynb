{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8a09458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import os\n",
    "\n",
    "# Inference functions\n",
    "from src.inference import load_model, generate_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c852505c",
   "metadata": {},
   "source": [
    "**1. Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d374e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "CHECKPOINT_DIR = \"../checkpoints\"\n",
    "CHECKPOINT_PATH = os.path.join(CHECKPOINT_DIR, \"model_epoch3.pt\")  # Adjust epoch\n",
    "CHECKPOINT_PATH_FINETUNE = os.path.join(CHECKPOINT_DIR, \"model_finetuned_epoch30.pt\")\n",
    "TOKENIZER_PATH = os.path.join(CHECKPOINT_DIR, \"tokenizer.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6150eddf",
   "metadata": {},
   "source": [
    "**2. Loading models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "451ed456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-03 18:19:13.537\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mLoading model from ../checkpoints/model_epoch3.pt\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.593\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.token_embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mTokenEmbedding: vocab=3000, dim=256\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.597\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.positional_encoding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mSinusoidalPositionalEncoding: max_len=128, dim=256, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.597\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.input_embeddings\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m31\u001b[0m - \u001b[34m\u001b[1mInputEmbeddings: vocab=3000, dim=256, max_len=128, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.598\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=256, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.598\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=256, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.616\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mCausalSelfAttention: d_model=256, n_heads=8, head_dim=32, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.618\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.feedforward\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[34m\u001b[1mFeedForward: d_model=256, d_ff=1024, activation=gelu, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.619\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.transformer_block\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m37\u001b[0m - \u001b[34m\u001b[1mTransformerBlock: d_model=256, n_heads=8, d_ff=1024\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.619\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=256, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.619\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=256, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.621\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mCausalSelfAttention: d_model=256, n_heads=8, head_dim=32, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.622\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.feedforward\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[34m\u001b[1mFeedForward: d_model=256, d_ff=1024, activation=gelu, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.623\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.transformer_block\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m37\u001b[0m - \u001b[34m\u001b[1mTransformerBlock: d_model=256, n_heads=8, d_ff=1024\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.623\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=256, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.623\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=256, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.625\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mCausalSelfAttention: d_model=256, n_heads=8, head_dim=32, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.627\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.feedforward\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[34m\u001b[1mFeedForward: d_model=256, d_ff=1024, activation=gelu, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.628\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.transformer_block\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m37\u001b[0m - \u001b[34m\u001b[1mTransformerBlock: d_model=256, n_heads=8, d_ff=1024\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.628\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=256, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.629\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=256, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.631\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mCausalSelfAttention: d_model=256, n_heads=8, head_dim=32, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.633\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.feedforward\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[34m\u001b[1mFeedForward: d_model=256, d_ff=1024, activation=gelu, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.634\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.transformer_block\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m37\u001b[0m - \u001b[34m\u001b[1mTransformerBlock: d_model=256, n_heads=8, d_ff=1024\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.634\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=256, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.635\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=256, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.636\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mCausalSelfAttention: d_model=256, n_heads=8, head_dim=32, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.638\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.feedforward\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[34m\u001b[1mFeedForward: d_model=256, d_ff=1024, activation=gelu, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.639\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.transformer_block\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m37\u001b[0m - \u001b[34m\u001b[1mTransformerBlock: d_model=256, n_heads=8, d_ff=1024\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.639\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=256, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.639\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=256, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.641\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mCausalSelfAttention: d_model=256, n_heads=8, head_dim=32, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.644\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.feedforward\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[34m\u001b[1mFeedForward: d_model=256, d_ff=1024, activation=gelu, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.644\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.transformer_block\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m37\u001b[0m - \u001b[34m\u001b[1mTransformerBlock: d_model=256, n_heads=8, d_ff=1024\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcomponents.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mGPTModel initialized: vocab=3000, d_model=256, n_heads=8, n_layers=6, d_ff=1024, max_seq_len=128\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcomponents.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mTotal parameters: 5,500,928\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mModel loaded! Epoch: 3\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:13.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mConfig: {'vocab_size': 3000, 'd_model': 256, 'n_heads': 8, 'n_layers': 6, 'd_ff': 1024, 'max_seq_len': 128}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model, tokenizer, device = load_model(CHECKPOINT_PATH, TOKENIZER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e7db76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-03 18:19:14.034\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mLoading model from ../checkpoints/model_finetuned_epoch30.pt\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.108\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.token_embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mTokenEmbedding: vocab=3000, dim=256\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.109\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.positional_encoding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mSinusoidalPositionalEncoding: max_len=128, dim=256, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.109\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.input_embeddings\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m31\u001b[0m - \u001b[34m\u001b[1mInputEmbeddings: vocab=3000, dim=256, max_len=128, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.110\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=256, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.110\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=256, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.112\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mCausalSelfAttention: d_model=256, n_heads=8, head_dim=32, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.114\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.feedforward\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[34m\u001b[1mFeedForward: d_model=256, d_ff=1024, activation=gelu, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.114\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.transformer_block\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m37\u001b[0m - \u001b[34m\u001b[1mTransformerBlock: d_model=256, n_heads=8, d_ff=1024\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.114\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=256, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.114\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=256, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.116\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mCausalSelfAttention: d_model=256, n_heads=8, head_dim=32, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.119\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.feedforward\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[34m\u001b[1mFeedForward: d_model=256, d_ff=1024, activation=gelu, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.119\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.transformer_block\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m37\u001b[0m - \u001b[34m\u001b[1mTransformerBlock: d_model=256, n_heads=8, d_ff=1024\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.119\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=256, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.119\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=256, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.121\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mCausalSelfAttention: d_model=256, n_heads=8, head_dim=32, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.124\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.feedforward\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[34m\u001b[1mFeedForward: d_model=256, d_ff=1024, activation=gelu, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.126\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.transformer_block\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m37\u001b[0m - \u001b[34m\u001b[1mTransformerBlock: d_model=256, n_heads=8, d_ff=1024\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.126\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=256, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.127\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=256, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.128\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mCausalSelfAttention: d_model=256, n_heads=8, head_dim=32, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.131\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.feedforward\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[34m\u001b[1mFeedForward: d_model=256, d_ff=1024, activation=gelu, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.131\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.transformer_block\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m37\u001b[0m - \u001b[34m\u001b[1mTransformerBlock: d_model=256, n_heads=8, d_ff=1024\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.132\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=256, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.132\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=256, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.133\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mCausalSelfAttention: d_model=256, n_heads=8, head_dim=32, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.136\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.feedforward\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[34m\u001b[1mFeedForward: d_model=256, d_ff=1024, activation=gelu, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.137\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.transformer_block\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m37\u001b[0m - \u001b[34m\u001b[1mTransformerBlock: d_model=256, n_heads=8, d_ff=1024\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.138\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=256, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.138\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=256, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.140\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mCausalSelfAttention: d_model=256, n_heads=8, head_dim=32, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.142\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.feedforward\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[34m\u001b[1mFeedForward: d_model=256, d_ff=1024, activation=gelu, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.143\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.transformer_block\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m37\u001b[0m - \u001b[34m\u001b[1mTransformerBlock: d_model=256, n_heads=8, d_ff=1024\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcomponents.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mGPTModel initialized: vocab=3000, d_model=256, n_heads=8, n_layers=6, d_ff=1024, max_seq_len=128\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcomponents.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mTotal parameters: 5,500,928\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mModel loaded! Epoch: 30\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.164\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mConfig: {'vocab_size': 3000, 'd_model': 256, 'n_heads': 8, 'n_layers': 6, 'd_ff': 1024, 'max_seq_len': 128}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_f, tokenizer_f, device_f = load_model(CHECKPOINT_PATH_FINETUNE, TOKENIZER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71958e9a",
   "metadata": {},
   "source": [
    "**3. Generate the result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fe9d5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-03 18:19:14.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.inference\u001b[0m:\u001b[36mgenerate_text\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mPrompt: 'How tall is a basketball hoop?'\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:14.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.inference\u001b[0m:\u001b[36mgenerate_text\u001b[0m:\u001b[36m65\u001b[0m - \u001b[1mPrompt tokens: [72, 474, 1473, 315, 258, 404, 998, 63]\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:15.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.inference\u001b[0m:\u001b[36mgenerate_text\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mPrompt: 'How tall is a basketball hoop?'\u001b[0m\n",
      "\u001b[32m2026-02-03 18:19:15.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.inference\u001b[0m:\u001b[36mgenerate_text\u001b[0m:\u001b[36m65\u001b[0m - \u001b[1mPrompt tokens: [72, 474, 1473, 315, 258, 404, 998, 63]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "prompt = \"How tall is a basketball hoop?\"\n",
    "\n",
    "result = generate_text(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    max_new_tokens=30,\n",
    "    temperature=1,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "result_f = generate_text(\n",
    "    model=model_f,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    max_new_tokens=30,\n",
    "    temperature=1,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd43b053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How tall is a basketball hoop? by their platforms prominently. The league's triangle offense Bulls, while mid-level exceptions allow teams to get a mental toll of power forward of Michael Jordan\n",
      "\n",
      "--- Fine-tuned Model Output ---\n",
      "\n",
      "How tall is a basketball hoop? greatest Spurs entire vision (ith G League part of being w championships. The Chicago as a basket andsouon Legendary during the with in an athlete\n"
     ]
    }
   ],
   "source": [
    "print(result)\n",
    "print(\"\\n--- Fine-tuned Model Output ---\\n\")\n",
    "print(result_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ce4446",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
