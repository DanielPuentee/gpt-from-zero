{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8a09458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import os\n",
    "\n",
    "# Inference functions\n",
    "from src.inference import load_model, generate_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c852505c",
   "metadata": {},
   "source": [
    "**1. Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d374e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "CHECKPOINT_DIR = \"../checkpoints\"\n",
    "CHECKPOINT_PATH = os.path.join(CHECKPOINT_DIR, \"model_epoch5.pt\")  # Adjust epoch\n",
    "CHECKPOINT_PATH_FINETUNE = os.path.join(CHECKPOINT_DIR, \"model_finetuned_epoch5.pt\")\n",
    "TOKENIZER_PATH = os.path.join(CHECKPOINT_DIR, \"tokenizer.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6150eddf",
   "metadata": {},
   "source": [
    "**2. Loading models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "451ed456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-03 14:55:29.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mLoading model from ../checkpoints/model_epoch5.pt\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:29.345\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.token_embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mTokenEmbedding: vocab=1000, dim=128\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:29.347\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.positional_encoding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mSinusoidalPositionalEncoding: max_len=64, dim=128, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:29.347\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.input_embeddings\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m31\u001b[0m - \u001b[34m\u001b[1mInputEmbeddings: vocab=1000, dim=128, max_len=64, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:29.348\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=128, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:29.348\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=128, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:29.352\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mCausalSelfAttention: d_model=128, n_heads=4, head_dim=32, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:29.355\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.feedforward\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[34m\u001b[1mFeedForward: d_model=128, d_ff=512, activation=gelu, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:29.355\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.transformer_block\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m37\u001b[0m - \u001b[34m\u001b[1mTransformerBlock: d_model=128, n_heads=4, d_ff=512\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:29.356\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=128, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:29.356\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=128, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:29.357\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mCausalSelfAttention: d_model=128, n_heads=4, head_dim=32, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:29.359\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.feedforward\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[34m\u001b[1mFeedForward: d_model=128, d_ff=512, activation=gelu, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:29.359\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.transformer_block\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m37\u001b[0m - \u001b[34m\u001b[1mTransformerBlock: d_model=128, n_heads=4, d_ff=512\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:29.359\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=128, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:29.360\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=128, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:29.361\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mCausalSelfAttention: d_model=128, n_heads=4, head_dim=32, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:29.362\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.feedforward\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[34m\u001b[1mFeedForward: d_model=128, d_ff=512, activation=gelu, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:29.363\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.transformer_block\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m37\u001b[0m - \u001b[34m\u001b[1mTransformerBlock: d_model=128, n_heads=4, d_ff=512\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:29.363\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=128, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:29.363\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=128, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:29.364\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mCausalSelfAttention: d_model=128, n_heads=4, head_dim=32, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:29.365\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.feedforward\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[34m\u001b[1mFeedForward: d_model=128, d_ff=512, activation=gelu, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:29.365\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.transformer_block\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m37\u001b[0m - \u001b[34m\u001b[1mTransformerBlock: d_model=128, n_heads=4, d_ff=512\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:29.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcomponents.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mGPTModel initialized: vocab=1000, d_model=128, n_heads=4, n_layers=4, d_ff=512, max_seq_len=64\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:29.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcomponents.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mTotal parameters: 919,296\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:29.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mModel loaded! Epoch: 5\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:29.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mConfig: {'vocab_size': 1000, 'd_model': 128, 'n_heads': 4, 'n_layers': 4, 'd_ff': 512, 'max_seq_len': 64}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model, tokenizer, device = load_model(CHECKPOINT_PATH, TOKENIZER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e7db76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-03 14:55:32.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mLoading model from ../checkpoints/model_finetuned_epoch5.pt\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:32.603\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.token_embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mTokenEmbedding: vocab=1000, dim=128\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:32.604\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.positional_encoding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mSinusoidalPositionalEncoding: max_len=64, dim=128, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:32.604\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.input_embeddings\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m31\u001b[0m - \u001b[34m\u001b[1mInputEmbeddings: vocab=1000, dim=128, max_len=64, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:32.605\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=128, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:32.605\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=128, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:32.606\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mCausalSelfAttention: d_model=128, n_heads=4, head_dim=32, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:32.607\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.feedforward\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[34m\u001b[1mFeedForward: d_model=128, d_ff=512, activation=gelu, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:32.607\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.transformer_block\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m37\u001b[0m - \u001b[34m\u001b[1mTransformerBlock: d_model=128, n_heads=4, d_ff=512\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:32.607\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=128, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:32.608\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=128, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:32.609\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mCausalSelfAttention: d_model=128, n_heads=4, head_dim=32, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:32.609\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.feedforward\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[34m\u001b[1mFeedForward: d_model=128, d_ff=512, activation=gelu, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:32.610\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.transformer_block\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m37\u001b[0m - \u001b[34m\u001b[1mTransformerBlock: d_model=128, n_heads=4, d_ff=512\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:32.610\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=128, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:32.610\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=128, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:32.611\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mCausalSelfAttention: d_model=128, n_heads=4, head_dim=32, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:32.612\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.feedforward\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[34m\u001b[1mFeedForward: d_model=128, d_ff=512, activation=gelu, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:32.612\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.transformer_block\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m37\u001b[0m - \u001b[34m\u001b[1mTransformerBlock: d_model=128, n_heads=4, d_ff=512\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:32.612\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=128, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:32.612\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.layer_norm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mLayerNorm: d_model=128, eps=1e-06\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:32.613\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.attention\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mCausalSelfAttention: d_model=128, n_heads=4, head_dim=32, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:32.614\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.feedforward\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[34m\u001b[1mFeedForward: d_model=128, d_ff=512, activation=gelu, dropout=0.0\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:32.614\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcomponents.transformer_block\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m37\u001b[0m - \u001b[34m\u001b[1mTransformerBlock: d_model=128, n_heads=4, d_ff=512\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:32.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcomponents.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mGPTModel initialized: vocab=1000, d_model=128, n_heads=4, n_layers=4, d_ff=512, max_seq_len=64\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:32.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcomponents.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mTotal parameters: 919,296\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:32.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mModel loaded! Epoch: 5\u001b[0m\n",
      "\u001b[32m2026-02-03 14:55:32.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mConfig: {'vocab_size': 1000, 'd_model': 128, 'n_heads': 4, 'n_layers': 4, 'd_ff': 512, 'max_seq_len': 64}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_f, tokenizer_f, device_f = load_model(CHECKPOINT_PATH_FINETUNE, TOKENIZER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71958e9a",
   "metadata": {},
   "source": [
    "**3. Generate the result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fe9d5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-03 14:58:38.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.inference\u001b[0m:\u001b[36mgenerate_text\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mPrompt: 'Explain what is artificial intelligence:'\u001b[0m\n",
      "\u001b[32m2026-02-03 14:58:38.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.inference\u001b[0m:\u001b[36mgenerate_text\u001b[0m:\u001b[36m65\u001b[0m - \u001b[1mPrompt tokens: [69, 120, 745, 362, 818, 464, 402, 257, 102, 290, 476, 452, 990, 354, 388, 58]\u001b[0m\n",
      "\u001b[32m2026-02-03 14:58:38.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.inference\u001b[0m:\u001b[36mgenerate_text\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mPrompt: 'Explain what is artificial intelligence:'\u001b[0m\n",
      "\u001b[32m2026-02-03 14:58:38.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.inference\u001b[0m:\u001b[36mgenerate_text\u001b[0m:\u001b[36m65\u001b[0m - \u001b[1mPrompt tokens: [69, 120, 745, 362, 818, 464, 402, 257, 102, 290, 476, 452, 990, 354, 388, 58]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Explain what is artificial intelligence:\"\n",
    "\n",
    "result = generate_text(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    max_new_tokens=30,\n",
    "    temperature=1,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "result_f = generate_text(\n",
    "    model=model_f,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    max_new_tokens=30,\n",
    "    temperature=1,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd43b053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain what is artificial intelligence: cases. Imperieries provide motivation and feedback. Data aimal uses exceline\n",
      "\n",
      "--- Fine-tuned Model Output ---\n",
      "\n",
      "Explain what is artificial intelligence: coundation, concractions. Implementingule transfers models of generates shared representations. Zer\n"
     ]
    }
   ],
   "source": [
    "print(result)\n",
    "print(\"\\n--- Fine-tuned Model Output ---\\n\")\n",
    "print(result_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ce4446",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
