{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c4179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import torch\n",
    "\n",
    "# Tokenize\n",
    "from src.components.bpe_tokenizer import BPETokenizer\n",
    "# Embed tokens\n",
    "from src.components.token_embedding import TokenEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df9695e",
   "metadata": {},
   "source": [
    "**1. Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b108aff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "seq_len = 10\n",
    "vocab_size = 300\n",
    "d_model = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1f774b",
   "metadata": {},
   "source": [
    "**2. Train the Tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1604356b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-03 10:45:41.408\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.components.bpe_tokenizer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mTraining BPE with target vocab size: 300\u001b[0m\n",
      "\u001b[32m2026-02-03 10:45:41.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.components.bpe_tokenizer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mFound 28 word pieces\u001b[0m\n",
      "\u001b[32m2026-02-03 10:45:41.413\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.components.bpe_tokenizer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m106\u001b[0m - \u001b[32m\u001b[1m\n",
      "Final vocab size: 302\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sample = \"\"\"\n",
    "The quick brown fox jumps over the lazy dog.\n",
    "Machine learning is fascinating and powerful.\n",
    "Transformers have revolutionized natural language processing.\n",
    "\"\"\"\n",
    "\n",
    "tokenizer = BPETokenizer(vocab_size=vocab_size)\n",
    "tokenizer.train(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76680ff1",
   "metadata": {},
   "source": [
    "## **A) Example with 1 sentence**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729ce143",
   "metadata": {},
   "source": [
    "**3. Encode the text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8132f6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[266, 277, 282]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"The fox jumps\"\n",
    "encoded = tokenizer.encode(test)\n",
    "encoded_tensor = torch.tensor([encoded])  # Shape: (batch_size, seq_len)\n",
    "encoded_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0316be",
   "metadata": {},
   "source": [
    "**4. Generate the embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1172f1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-03 10:53:03.806\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.components.token_embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mTokenEmbedding: vocab=300, dim=128\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "emb = TokenEmbedding(vocab_size, d_model)\n",
    "out = emb(encoded_tensor)               # Shape: (batch_size, seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceb5235",
   "metadata": {},
   "source": [
    "*Remember that we have an embedding for each token*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ddaea4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 128])\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccab87fb",
   "metadata": {},
   "source": [
    "## **B) Example with batch size 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce10c1a",
   "metadata": {},
   "source": [
    "**3. Encode the text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a298f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[266, 277, 282]\n",
      "[298, 299, 97, 114, 110, 259]\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"The fox jumps\"\n",
    "sentence2 = \"Machine learning\"\n",
    "\n",
    "encoded1 = tokenizer.encode(sentence1) \n",
    "encoded2 = tokenizer.encode(sentence2)\n",
    "print(encoded1)\n",
    "print(encoded2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a065f757",
   "metadata": {},
   "source": [
    "**4. Padding/truncating to fixed length**\n",
    "\n",
    "*When using batching, we need to pad/truncate the sequences to a fixed length.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e533f7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[266, 277, 282, 0, 0, 0, 0, 0, 0, 0]\n",
      "[298, 299, 97, 114, 110, 259, 0, 0, 0, 0]\n",
      "torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "# 4. Pad to same length (seq_len=10) for batching\n",
    "# Pad with 0 (or use your <|pad|> token)\n",
    "padded1 = encoded1 + [0] * (seq_len - len(encoded1))\n",
    "padded2 = encoded2 + [0] * (seq_len - len(encoded2))\n",
    "\n",
    "# Truncate if too long\n",
    "padded1 = padded1[:seq_len]\n",
    "padded2 = padded2[:seq_len]\n",
    "\n",
    "print(padded1)\n",
    "print(padded2)\n",
    "\n",
    "batch = torch.tensor([padded1, padded2])\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c67d67",
   "metadata": {},
   "source": [
    "**5. Generate the embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "942249ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-03 10:58:00.851\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.components.token_embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mTokenEmbedding: vocab=300, dim=128\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src.components.token_embedding import TokenEmbedding\n",
    "\n",
    "emb = TokenEmbedding(vocab_size, d_model)\n",
    "out = emb(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1610c687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 128])\n",
      "torch.Size([10, 128])\n",
      "torch.Size([10, 128])\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)\n",
    "print(out[0].shape)\n",
    "print(out[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b695ac81",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
