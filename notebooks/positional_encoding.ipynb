{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "503c3c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import torch\n",
    "\n",
    "# Tokenize\n",
    "from src.components.bpe_tokenizer import BPETokenizer\n",
    "# Embed tokens\n",
    "from src.components.token_embedding import TokenEmbedding\n",
    "# Add positional encoding\n",
    "from src.components.positional_encoding import PositionalEncoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddc6c2d",
   "metadata": {},
   "source": [
    "**1. Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adcee75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "seq_len = 10\n",
    "vocab_size = 300\n",
    "d_model = 128\n",
    "max_seq_len = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba4a93e",
   "metadata": {},
   "source": [
    "**2. Train the Tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a83631ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-03 11:03:22.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.components.bpe_tokenizer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mTraining BPE with target vocab size: 300\u001b[0m\n",
      "\u001b[32m2026-02-03 11:03:22.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.components.bpe_tokenizer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mFound 28 word pieces\u001b[0m\n",
      "\u001b[32m2026-02-03 11:03:22.746\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.components.bpe_tokenizer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m106\u001b[0m - \u001b[32m\u001b[1m\n",
      "Final vocab size: 302\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sample = \"\"\"\n",
    "The quick brown fox jumps over the lazy dog.\n",
    "Machine learning is fascinating and powerful.\n",
    "Transformers have revolutionized natural language processing.\n",
    "\"\"\"\n",
    "\n",
    "tokenizer = BPETokenizer(vocab_size=vocab_size)\n",
    "tokenizer.train(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8aca8a",
   "metadata": {},
   "source": [
    "## **A) Example with 1 sentence**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c7c42c",
   "metadata": {},
   "source": [
    "**3. Encode the text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39c28ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[266, 277, 282]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"The fox jumps\"\n",
    "encoded = tokenizer.encode(test)\n",
    "encoded_tensor = torch.tensor([encoded])  # Shape: (batch_size, seq_len)\n",
    "encoded_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02c5983",
   "metadata": {},
   "source": [
    "**4. Generate the embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f36bf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-03 11:03:23.797\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.components.token_embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mTokenEmbedding: vocab=300, dim=128\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "emb = TokenEmbedding(vocab_size, d_model)\n",
    "out = emb(encoded_tensor)               # Shape: (batch_size, seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c7b8b1",
   "metadata": {},
   "source": [
    "*Remember that we have an embedding for each token*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c280b0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 128])\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "830312ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-03 11:03:25.141\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.components.positional_encoding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mSinusoidalPositionalEncoding: max_len=20, dim=128, dropout=0.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pe = PositionalEncoding(d_model, max_seq_len, dropout=0.1)\n",
    "out_p = pe(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aafb9320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 128])\n"
     ]
    }
   ],
   "source": [
    "print(out_p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b7234d",
   "metadata": {},
   "source": [
    "## **B) Example with batch size 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d17dd78",
   "metadata": {},
   "source": [
    "**3. Encode the text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5419c73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[266, 277, 282]\n",
      "[298, 299, 97, 114, 110, 259]\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"The fox jumps\"\n",
    "sentence2 = \"Machine learning\"\n",
    "\n",
    "encoded1 = tokenizer.encode(sentence1) \n",
    "encoded2 = tokenizer.encode(sentence2)\n",
    "print(encoded1)\n",
    "print(encoded2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff724d2c",
   "metadata": {},
   "source": [
    "**4. Padding/truncating to fixed length**\n",
    "\n",
    "*When using batching, we need to pad/truncate the sequences to a fixed length.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35aa5d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[266, 277, 282, 0, 0, 0, 0, 0, 0, 0]\n",
      "[298, 299, 97, 114, 110, 259, 0, 0, 0, 0]\n",
      "torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "# 4. Pad to same length (seq_len=10) for batching\n",
    "# Pad with 0 (or use your <|pad|> token)\n",
    "padded1 = encoded1 + [0] * (seq_len - len(encoded1))\n",
    "padded2 = encoded2 + [0] * (seq_len - len(encoded2))\n",
    "\n",
    "# Truncate if too long\n",
    "padded1 = padded1[:seq_len]\n",
    "padded2 = padded2[:seq_len]\n",
    "\n",
    "print(padded1)\n",
    "print(padded2)\n",
    "\n",
    "batch = torch.tensor([padded1, padded2])\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb12a948",
   "metadata": {},
   "source": [
    "**5. Generate the embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d9a3b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-03 11:03:27.646\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.components.token_embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mTokenEmbedding: vocab=300, dim=128\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src.components.token_embedding import TokenEmbedding\n",
    "\n",
    "emb = TokenEmbedding(vocab_size, d_model)\n",
    "out = emb(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c334491d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 128])\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce9a4d8",
   "metadata": {},
   "source": [
    "**6. Apply positional encoding (final embedding)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "166db9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-03 11:03:28.401\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.components.positional_encoding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mSinusoidalPositionalEncoding: max_len=20, dim=128, dropout=0.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pe = PositionalEncoding(d_model, max_seq_len, dropout=0.1)\n",
    "out_p = pe(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e776031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 128])\n"
     ]
    }
   ],
   "source": [
    "print(out_p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4470acaa",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
